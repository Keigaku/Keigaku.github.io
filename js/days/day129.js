// ===========================
// Day 129: 分散分析と回帰分析
// ===========================
window.Day129 = {
    render(container, dayNum) {
        const dayInfo = Navigation.days[dayNum - 1];
        const sections = `
            <div class="content-section animate-in">
                <h2>📈 分散分析 (ANOVA: Analysis of Variance)</h2>
                <div class="info-box">
                    <div class="info-box-title">📋 3つ以上の「平均」の差を検定する</div>
                    <p>t検定では「A班とB班」のように2つのグループの平均値の差しか比較できません。<br>「営業部、開発部、総務部」など、<strong>3つ以上</strong>のグループ間で平均値に有意な差があるかを一度に調べるのが分散分析（ANOVA）です。名前に反してテストするのは「平均の差」です。</p>
                </div>
                
                <h3>一元配置分散分析の仕組み</h3>
                <p>データのばらつき（変動）を、以下の2つに「分解」して比較します。</p>
                <ul class="feature-list">
                    <li><strong>要因変動 (群間変動)</strong>: グループ（水準）間の平均の違いによるばらつき。<br>「営業部と開発部で全体の平均設定値が違うから生じる差」</li>
                    <li><strong>残差変動 (群内変動・誤差変動)</strong>: 同じグループ内での個人差によるばらつき。<br>「同じ営業部でもAさんとBさんで成績が違う差」</li>
                </ul>

                <p><strong>【F検定】</strong></p>
                $$ F = \\frac{\\text{要因の分散}}{\\text{誤差の分散}} $$
                <p>このF値が基準より大きければ（誤差による偶然のばらつきよりも、グループ間の明確な違いのせいだ！と言えるなら）「グループ間に有意な差がある」と判定します。</p>

                <div class="info-box tip">
                    <div class="info-box-title">💡 分散分析表の読み方（2級頻出）</div>
                    <p>自由度の計算がよく問われます。<br>
                    全データ数 = $N$、グループ（水準）数 = $k$<br>
                    ・要因（群間）の自由度 = $k - 1$<br>
                    ・誤差（群内）の自由度 = $N - k$<br>
                    ・全体の自由度 = $N - 1$</p>
                </div>
            </div>

            <div class="content-section animate-in stagger-1">
                <h2>📉 回帰分析 (Regression Analysis)</h2>
                <p>2つの変数（XとY）の関係を一次関数の直線（回帰直線）でモデル化し、XからYを予測する手法です。金融での株価予測モデル（ベータ）の基礎となります。</p>

                <h3>単回帰モデルと最小二乗法</h3>
                <p>モデル式:</p>
                $$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i $$
                <ul>
                    <li><strong>$y$ (目的変数)</strong>: 予測したい値（例：明日の株価リターン）</li>
                    <li><strong>$x$ (説明変数)</strong>: 予測に使う値（例：市場全体のリターン）</li>
                    <li><strong>$\\beta_1$ (回帰係数)</strong>: 直線の傾き（感応度）。</li>
                    <li><strong>$\\varepsilon$ (誤差・残差)</strong>: 直線では説明しきれずズレた分。</li>
                </ul>
                <p><strong>最小二乗法 (OLS)</strong>: 実際のデータと、直線の予測値との「ズレ（残差）の2乗の合計」が最も小さくなるように、直線の傾き $\\beta_1$ と切片 $\\beta_0$ を決める方法です。</p>
                <p><small style="color:var(--accent-purple);">※偏回帰係数 $\\beta_1$ = 共分散($X,Y$) / Xの分散</small></p>

                <h3>決定係数 ($R^2$)</h3>
                <p>引いた回帰直線が、「どれだけYのばらつきをうまく説明できているか」を示す指標（0〜1）。<br>
                「$R^2 = 0.8$」 ならば、「Yの変動の80%はXによって（この直線で）説明できている（当てはまりが良い）」という意味です。</p>
            </div>

            <div id="day129-quiz"></div>
        `;
        Navigation.renderDayTemplate(container, dayNum, dayInfo, sections);

        QuizEngine.render('day129-quiz', 'day129-quiz', [
            { question: '4つの店舗（A店、B店、C店、D店）で、新しい販売マニュアルの効果を比較するため、それぞれ10人ずつ（合計40人）の販売員にテストを行い、点数を記録しました。一元配置分散分析を用いて「店舗間で平均点に有意な差があるか」を検定する際の、「群間（要因）の自由度」と「群内（誤差）の自由度」はそれぞれいくつですか？', options: ['群間: 3、群内: 36', '群間: 4、群内: 39', '群間: 3、群内: 40', '群間: 4、群内: 36'], correct: 0, explanation: '一元配置分散分析の自由度の計算です。<br>・グループ（水準）数 k = 4。群間の自由度は k - 1 = 4 - 1 = 3 です。<br>・全データ数 N = 40。群内の自由度は N - k = 40 - 4 = 36 です。<br>（全体の自由度は N - 1 = 39）' },
            { question: '分散分析（ANOVA）において、帰無仮説が棄却された（「グループ間に有意な差がある」と判定された）場合、この結果から「確実」に言えることはどれですか？', options: ['すべてのグループの平均値が、互いにすべて異なっている。', '最も平均が高いグループと、最も平均が低いグループの間のみに差がある。', '少なくとも1つのグループの平均値は、他のグループの平均値と異なる。', 'ばらつき（分散）がグループ間で異なっている。'], correct: 2, explanation: '分散分析（F検定）の帰無仮説は「すべてのグループの平均が等しい（μ1 = μ2 = μ3 = ... = μk）」です。<br>これが棄却された場合、結論は「すべてが等しいわけではない」つまり「少なくともどれか1つのグループの平均は他と違う」という事になります。具体的にどのグループとどのグループに差があるかを知るには、事後検定（多重比較）を追加で行う必要があります。' },
            { question: '単回帰分析において「最小二乗法」という手法が最小にしようとしているのは何ですか？', options: ['説明変数(x)の分散', '実測値(y)と回帰直線上での予測値(ŷ)との差（残差）の絶対値の合計', '実測値(y)と回帰直線上での予測値(ŷ)との差（残差）のそれぞれの2乗の合計', '決定係数 (R²)'], correct: 2, explanation: '最小二乗法（OLS, Ordinary Least Squares）は、各データ点と、引いた直線上の予測値とのズレ（残差：Residuals）をそれぞれ「2乗」し、その合計（残差平方和）がもっとも『小さく（最小に）』なるような直線を引く手法です。絶対値ではありません。' },
            { question: 'ある店舗の「気温(X)」と「アイスクリームの売上(Y)」の単回帰分析を行ったところ、回帰方程式が y = 15x + 100 となり、決定係数(R²) は 0.81 でした。この結果の解釈として正しいものはどれですか？', options: ['気温が1度上がると、売上は平均して81円上がる。', 'アイスの売上のばらつきのうち、15%が気温によって説明される。', 'アイスの売上のばらつきのうち、約81%が気温によって説明できる（当てはまりの良さ）。', '気温と売上の相関係数は 0.65 である。'], correct: 2, explanation: '決定係数 (R²) は「モデルの当てはまりの良さ」を示し、目的変数(Y)の全変動のうち、回帰直線（説明変数X）によって説明できた割合を意味します。R²=0.81なので、81%が気温で説明できたことになります。<br>※単回帰分析の場合、決定係数はピアソンの相関係数 r の2乗になるため、相関係数 r は √0.81 = 0.9 または -0.9 です（回帰係数がプラス=15なので r=0.9 です）。' }
        ]);

        // KaTeX rendering for math formulas
        if (window.renderMathInElement) {
            renderMathInElement(container, {
                delimiters: [
                    { left: '$$', right: '$$', display: true },
                    { left: '$', right: '$', display: false }
                ]
            });
        }
    }
};
