// ===========================
// Day 135: 多変量解析と1級総合演習
// ===========================
window.Day135 = {
    render(container, dayNum) {
        const dayInfo = Navigation.days[dayNum - 1];
        const sections = `
            <div class="content-section animate-in">
                <h2>🌐 多変量解析 (Multivariate Analysis)</h2>
                <div class="info-box">
                    <div class="info-box-title">📋 複雑なデータの背後にある「構造」を見抜く</div>
                    <p>身長、体重、年齢、血圧... といった多数の変数（多次元データ）を同時に扱い、要約や分類を行う手法群です。機械学習の「教師なし学習」等とも深く関連します。</p>
                </div>
                
                <h3>主成分分析 (Principal Component Analysis: PCA)</h3>
                <p><strong>次元圧縮</strong>の代表選手です。相関のある多数の変数を、互いに無相関で、元のデータが持つ「分散（ばらつき・情報）」をなるべく多く説明できる少数の新しい変数（主成分）に合成します。</p>
                <div style="background: var(--bg-card); padding: 1rem; border-left: 4px solid var(--accent-blue);">
                    <p>数学的には、データの<strong>分散共分散行列（または相関行列）の「固有値と固有ベクトル」を求める問題</strong>に帰着します。<br>
                    固有ベクトルが新しい軸の「方向」となり、対応する固有値がその軸が説明できる「分散の大きさ（寄与率）」になります。</p>
                </div>

                <h3>判別分析 (Discriminant Analysis)</h3>
                <p>あらかじめグループ（例：優良顧客と倒産企業）が分かっているデータから、未知のデータがどのグループに属するかを予測する「境界線（判別関数）」を作る手法です。</p>
                <ul class="feature-list">
                    <li><strong>線形判別分析 (LDA):</strong> 2グループ間で「（判別軸に投影したときの）グループ間の分散（違い）を最大化し、かつ、グループ内の分散（個人差）を最小化する」ような最適な直線を求めます。</li>
                </ul>
            </div>

            <div class="content-section animate-in stagger-1">
                <h2>🏆 統計検定1級 総合演習（キャップストーン）</h2>
                <p>以上で、Day 131〜135 にわたる「統計検定1級」のコア・エッセンスの学習が完了しました。<br>
                1級の壁は高く、数式の証明が主になりますが、本質的にやっていることは以下の3つに集約されます。</p>

                <ol>
                    <li><strong>現象を確率モデル（分布）に落とし込む</strong></li>
                    <li><strong>そのモデルのパラメータを、データから最も尤もらしく「推定」する (MLEなど)</strong></li>
                    <li><strong>その推定結果が本当に信頼できるか、理論に基づいて「検定」する (尤度比検定など)</strong></li>
                </ol>

                <p style="text-align:center; font-size:1.1rem; font-weight:bold; margin-top:2rem; color:var(--accent-purple);">
                    統計的モデリングと理論的背景（数理統計学）への深い理解は、<br>
                    ブラックボックスなAI・機械学習時代において、最強の「ホワイトボックス化の武器」となります。
                </p>
            </div>

            <div id="day135-quiz"></div>
        `;
        Navigation.renderDayTemplate(container, dayNum, dayInfo, sections);

        QuizEngine.render('day135-quiz', 'day135-quiz', [
            { question: '主成分分析（PCA）において、「第1主成分」とはどのような性質を持つ新しい変数として決定されますか？', options: ['元のすべての変数の「平均値」に一致する変数', '元のデータの「ばらつき（分散・情報量）」を最も大きく保持（最大化）する方向の合成変数', '元のデータの欠損値を最も高い確率で補完できる変数', 'データの中で最も「外れ値（異常値）」を示すデータ点だけを抽出した変数'], correct: 1, explanation: '主成分分析は、次元を減らしても「なるべく元のデータの情報（ばらつき・分散）を失わない」ように新しい軸を探すアルゴリズムです。<br>したがって「第1主成分」は、データの分散が最大となる方向（分散共分散行列の最大の固有値に対応する固有ベクトル）に設定されます。' },
            { question: '主成分分析において、各主成分が「元のデータの全体ばらつき（全分散）のうち、どのくらいの割合を説明できているか」を示す指標を何と呼びますか？', options: ['自由度', '尤度比', '決定係数 (R²)', '寄与率 (Contribution Rate)'], correct: 3, explanation: '各主成分の固有値を、すべての固有値の合計（全分散）で割ったものを「寄与率（プロポーション・オブ・バリアンス）」と呼びます。<br>例えば「第1主成分の寄与率が60%、第2主成分の寄与率が25%」であれば、「累積寄与率85%」となり、「2つの新しい変数（2次元）だけで、元の複雑なデータの85%の情報を説明できている」と判断します。' },
            { question: 'ある多変量データにおいて「判別分析（フィッシャーの線形判別）」を行う際の基本的な指針（目的関数の設計）として、正しいものを表す概念はどれですか？', options: ['各グループ間の重心ができるだけ近づき（群間変動最小）、各グループ内の分散ができるだけ離れる（群内変動最大）ように判別係数を決める。', '各グループ間のデータのユークリッド距離の総和が「定数」になるように判別直線を引く。', '各グループの重心（平均）間の距離（分散）が「最大」となり、かつ同じグループ内のデータのばらつき（分散）が「最小」となるような「最もグループを切り分けやすい軸」を見つける。', '回帰直線の残差平方和がゼロになる決定的な平面を見つける手法。'], correct: 2, explanation: 'フィッシャーの線形判別分析における最強の判別軸（境界線のもと）の探し方は、「群間分散（グループ同士の離れ具合）」を重きの分子に置き、「群内分散（各グループ内でのバラツキ具合）」を分母に置き、この『群間変動 / 群内変動』の比を【最大化】することです。つまり「グループ同士は遠く離れ、グループ内はギュッと密集している」状態が理想の切り分け方になります。' },
            { question: '【総合復習】統計検定1級（数理統計学）の世界において、「手元のデータ（サンプル）x から、未知のパラメータ θ を推定したい」とき、最も汎用的で強力なアプローチとされている「データが得られた事象の確率（密度）関数の積を θ の関数とみなし、これを最大化する θ を探す」手法を何と呼びますか？', options: ['最小二乗法 (OLS)', '最尤推定法 (MLE)', 'モーメント積率法 (Method of Moments)', '分位点回帰'], correct: 1, explanation: '「このデータが手元に集まったのは、あるパラメータθのもとで最も起こりやすかった（尤もらしかった）からであるはずだ」という逆算的な思想に基づくのが「最尤推定法 (Maximum Likelihood Estimation)」です。<br>数学的性質（一致性、漸近正規性、漸近有効性）が素晴らしいため、現代の統計的モデリングにおける推定量計算の王者として君臨しています。' }
        ]);

        // MathJax rendering for dynamically added content
        if (window.MathJax) {
            MathJax.typesetPromise([container]);
        }
    }
};
