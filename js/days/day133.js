// ===========================
// Day 133: 検定理論と漸近理論
// ===========================
window.Day133 = {
    render(container, dayNum) {
        const dayInfo = Navigation.days[dayNum - 1];
        const sections = `
            <div class="content-section animate-in">
                <h2>⚖️ 検定の理論 (Testing Theory)</h2>
                <div class="info-box">
                    <div class="info-box-title">📋 「最強の検定」の作り方</div>
                    <p>仮説検定において、有意水準（第1種の誤りを犯す確率 $\\alpha$）を一定の 0.05 以下に保ったまま、<strong>検出力（第2種の誤りを犯さない確率 $1-\\beta$）を最大化する</strong>検定を「一様最強力検定 (UMP test)」と呼びます。1級では、この最強の検定方式を数学的に導出します。</p>
                </div>
                
                <h3>ネイマン＝ピアソンの補題 (Neyman-Pearson Lemma)</h3>
                <p>単純仮説（例：$H_0: \\mu = 0$  vs  $H_1: \\mu = 1$ のようにピッタリ値が指定されたもの）に対する「最強力検定」を与える定理です。<br>
                結論として、以下の<strong>尤度比（Likelihood Ratio）</strong>を使って棄却域を決めるのが、どんな方法よりも検出力が高くなる（最強である）と証明されました。</p>

                <div style="background: var(--bg-card); padding: 1.5rem; border: 1px solid var(--border-color); border-radius: var(--radius-md); text-align:center;">
                    <code>$$ \\lambda = \\frac{ L(\\theta_1; x) }{ L(\\theta_0; x) } > k $$</code><br>
                    <small>（帰無仮説の時の尤度 より 対立仮説の時の尤度 の方が $k$ 倍以上大きければ棄却せよ）</small>
                </div>
            </div>

            <div class="content-section animate-in stagger-1">
                <h2>📊 尤度比検定 (Likelihood Ratio Test)</h2>
                <p>上記の補題を、複合仮説（例：$H_0: \\theta \\le 0$  vs  $H_1: \\theta > 0$ のように範囲を持つもの）にも拡張した、汎用的な検定手法です。</p>
                <p>全体のパラメータ空間で最大化した尤度（一番尤もらしい値）と、帰無仮説の条件という縛りを入れた状態で最大化した尤度の「比」をとります。縛りを入れたせいで著しく尤度が下がったなら、「帰無仮説の縛りは間違っている」として棄却します。</p>

                <h3>ウィルクスの定理 (Wilks' Theorem)</h3>
                <p>尤度比 $\\Lambda$ を使って作った検定統計量 <code>$-2 \\log \\Lambda$</code> は、サンプルサイズ $n$ が大きいとき、近似的に <strong>カイ二乗($\\chi^2$)分布</strong> に従うという、1級・実務における超強力な漸近理論です。</p>
            </div>

            <div class="content-section animate-in stagger-2">
                <h2>델타 デルタ法と漸近理論 (Asymptotic Theory)</h2>
                <p>「標本平均が正規分布になるのは中心極限定理で分かった。じゃあ、平均の2乗だったり、log(平均) みたいに<strong>関数を通した値</strong>の分布はどうなるの？」に答えるのがデルタ法です。</p>
                
                <p>テイラー展開の1次近似を利用し、変数変換後の漸近分散（データ数が多い極限でのばらつき）を計算する、1級の計算問題の超頻出テクニックです。<br>
                関数 $g(x)$ を通した場合、元の分散に近似的に <strong>$[g'(\\mu)]^2$</strong> （微分したものの2乗）が掛けられます。</p>
            </div>

            <div id="day133-quiz"></div>
        `;
        Navigation.renderDayTemplate(container, dayNum, dayInfo, sections);

        QuizEngine.render('day133-quiz', 'day133-quiz', [
            { question: '仮説検定において、ある有意水準 α のもとで「第1種の誤りを α 以下に抑えつつ、第2種の誤りをする確率 β を最も小さくする（＝検出力 1-β を最大にする）」検定手法のことを何と呼びますか？', options: ['一様最小分散不偏検定 (UMVU)', '最強力検定 (Most Powerful test)', '尤度比検定 (Likelihood Ratio test)', '無情報検定'], correct: 1, explanation: '有意水準を固定した条件のもとで、真犯人を逃がさない確率（検出力）が最も高くなる、パワーの最強な検定を「最強力検定」と呼びます。<br>ネイマン・ピアソンの補題は、この最強力検定が「尤度比」による棄却で達成されることを数学的に証明した統計学上の金字塔です。' },
            { question: '尤度比検定において、帰無仮説の制約下での最大尤度を L_0、制約なし（パラメータ空間全体）での最大尤度を L_max とし、尤度比を Λ = L_0 / L_max とします。<br>このとき、ウィルクスの定理によれば、サンプルサイズ n が大きい極限において、統計量「 -2 log Λ 」は【何の分布】に漸近的に近似されますか？　（AIC=Akaike Information Criterionの導出などにも繋がる重要定理です）', options: ['標準正規分布 N(0,1)', '漸近 t分布', 'カイ二乗 (χ²) 分布', 'F分布'], correct: 2, explanation: 'Wilksの定理により、尤度比から作られる統計量 -2 log Λ は、漸近的に「カイ二乗（χ²）分布」に従うことが証明されています。自由度は [制約なしパラメータの数 - 制約下パラメータの数] となります。<br>これを利用することで、真の分布の形を知らなくても、χ²分布表を使って巨大なデータサンプルの尤度比検定を簡単に行うことができます。' },
            { question: 'デルタ法（Delta method）に関する説明として、最も適切なものはどれですか？', options: ['標本平均などの推定量 Xn が正規分布 N(μ, σ²/n) に漸近するとき、滑らかな関数 g(x) を用いた g(Xn) もまた正規分布に漸近し、その分散は元の分散の [g\'(μ)]² 倍でおおよそ近似できるという定理。', '未知の確率分布の尤度関数を数値演算アルゴリズムによってシミュレーションし、近似する手法。', '少数のサンプル (n<30) からでも、正確な母分散を推定するための補正法。', '第1種の誤りと第2種の誤りのバランス（デルタ）を最適化し、損失関数を最小化するための分析手法。'], correct: 0, explanation: 'デルタ法は、テイラー展開の1次の項までの近似（線形近似）を利用し、「平均の関数（例えば標本平均の対数や平方根）」の漸近的な確率分布（期待値と分散）を求めるテクニックです。<br>元の推定量が正規分布に従う（中心極限定理）なら、それを関数gに通したものも正規分布に従うとし、分散は元の分散に [ 1階微分の2乗 ] を掛けたものになる、というのが結論です。' },
            { question: '尤度比検定（LRT）、ワルド検定（Wald test）、および スコア検定（ラグランジュ乗数検定, LM test）の、いわゆる「3大検定」に関して、サンプルサイズ n が限りなく大きい（漸近的）状況では、これらの検定はどうなりますか？', options: ['LRTが常に最も高い検出力（1に近い）を持つ。', 'Wald検定のみがカイ二乗分布に従い、他は正規分布に従う。', '3つの検定手法から得られる検定統計量の値と棄却の結論は、局所的な対立仮説のもとで漸近的に同等（一致）になる。', 'スコア検定は計算不可となるため、LRTとWald検定のみが使われる。'], correct: 2, explanation: '統計検定1級レベルでは、尤度関数の形状（頂点の高さ＝LRT、頂点からの横の距離＝Wald、指定点での接線の傾き＝Score）のどこに注目するかで3つの検定が導出されますが、n が無限大に漸近する極限においては「この3つの検定方法は数学的に同値となり、同じχ²分布に従い、一致した結論を出す（漸近同等性）」という美しい事実が成立します。' }
        ]);

        // MathJax rendering for dynamically added content
        if (window.MathJax) {
            MathJax.typesetPromise([container]);
        }
    }
};
